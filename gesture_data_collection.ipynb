{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to collect and save the training data for the hand gesture detection program. We use OpenCV to load our camera and view the keypoints before saving them, and Google's mediapipe library to detect the hands and keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "\n",
    "#Adjust the variables below to specify the number and names of the classes\n",
    "num_classes = 6\n",
    "class_names = [\"one\", \"two\", \"three\", \"four\", \"five\", \"other\"]\n",
    "\n",
    "def get_training_landmarks(landmarks):\n",
    "    landmarks_list = []\n",
    "    for landmark in landmarks:\n",
    "        landmarks_list.append([landmark.x, landmark.y, landmark.z])\n",
    "    return landmarks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below can be used to collect the training data for each class. Pass the class id as the argument for the class that you want to collect the training data for. For eg, if you want to collect training data for the first class, run the function as 'collectClassTrainingData(0)' .\n",
    "\n",
    "After running the function, raise your hand in front of the camera. When it is detected by the mediapipe library, a new window will open which will show your camera view and the keypoints on the detected hand. Make the particular gesture and press Space to save the keypoints for that gesture. Try saving keypoints from multiple angles and both hands so that the model, which will be trained later, can effectively detect that gesture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"\" #Add path to the directory where you wish to save the csv files with the training data\n",
    "\n",
    "def collectClassTrainingData(class_id):\n",
    "    writer = csv.writer(open(save_dir + str(class_id) +\n",
    "                             \".csv\", 'a', newline = ''))\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(max_num_hands = 1, min_detection_confidence = 0.7, min_tracking_confidence = 0.6)\n",
    "\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        valid, img = cam.read()\n",
    "        if not valid:\n",
    "            print(\"Failed to grab frame, closing..\")\n",
    "            break\n",
    "\n",
    "        img = cv2.cvtColor(cv2.flip(img, 1), cv2.COLOR_BGR2RGB)\n",
    "        img.flags.writeable = False # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "        results = hands.process(img)\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        # Draw the hand annotations on the image.\n",
    "        if(results.multi_hand_landmarks):\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            cv2.imshow(\"Landmark Hands\", img)\n",
    "\n",
    "        k = cv2.waitKey(1)\n",
    "        if k%256 == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        elif k%256 == 32:\n",
    "            # SPACE pressed\n",
    "            if(results.multi_hand_landmarks):\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    handedness = results.multi_handedness[0].classification[0].index\n",
    "                    landmark_list = get_training_landmarks(hand_landmarks.landmark)\n",
    "                    landmark_list.insert(0, class_id)\n",
    "                    landmark_list.insert(1, handedness)\n",
    "                    writer.writerow(landmark_list)\n",
    "            else:\n",
    "                print(\"No hand detected\")\n",
    "        #elif k%256 == 112:\n",
    "\n",
    "    hands.close()\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "collectClassTrainingData(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
